{
  "hash": "e3cecfb4d9f06fc4e64e11271c33d9b3",
  "result": {
    "engine": "knitr",
    "markdown": "---\nformat: html\n---\n\n\n\n<center>\n\n::: text\n\n## Uses too many big words\n\nBelow is a word cloud of Seth Milchick's most frequently used words of the past \\[*few*\\] quarter\\[*s*\\] alone. \\[*Lumon*\\] recommended that Mr. Milchick begin simplifying his language so as to achieve clearer comprehension from his subordinates and peers.\n\nLumon claimed (as detailed above) that Milchick is using too many big words. *I don't see evidence of this!*\n:::\n\n</center>\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(mdr)\nlibrary(tidytext)\nlibrary(tidyverse)\nlibrary(wordcloud2)\nlibrary(textclean)\nlibrary(ggiraph)\nlibrary(lexicon)\n\nset.seed(266)\n\ntranscripts |> \n  filter(grepl(\"Mil\", speaker)) |>\n  mutate(\n    dialogue = str_replace_all(dialogue, \"’\", \"'\"),\n    dialogue = replace_contraction(dialogue)\n  ) |>\n  unnest_tokens(word, dialogue) |>\n  anti_join(stop_words, by = \"word\") |>\n  filter(!word %in% c(\"ms\", \"miss\", \"b's\"), !str_detect(word, \"\\\\d\")) |>\n  mutate(word = gsub(\"'s\", \"\", word)) |>\n  count(word) |>\n  filter(n > 2) |>\n  arrange(desc(n)) |>\n  wordcloud2(backgroundColor = \"#030303\",\n             fontFamily = \"Noto Sans Mono\",\n             size = 0.8)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"wordcloud2 html-widget html-fill-item\" id=\"htmlwidget-2756f79f2ee279509ac0\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-2756f79f2ee279509ac0\">{\"x\":{\"word\":[\"dylan\",\"mark\",\"irving\",\"helly\",\"outie\",\"time\",\"cobel\",\"innie\",\"office\",\"kier\",\"lumon\",\"morning\",\"day\",\"hey\",\"burt\",\"feel\",\"huang\",\"mdr\",\"refiners\",\"scout\",\"party\",\"severed\",\"eagan\",\"hope\",\"afraid\",\"company\",\"experience\",\"floor\",\"happy\",\"milchick\",\"ready\",\"remember\",\"seat\",\"stop\",\"word\",\"ahead\",\"call\",\"called\",\"department\",\"dieter\",\"enjoy\",\"evening\",\"eyes\",\"fire\",\"happened\",\"hate\",\"head\",\"hollow\",\"life\",\"love\",\"meantime\",\"night\",\"rest\",\"return\",\"special\",\"start\",\"stay\",\"team\",\"told\",\"balloons\",\"brother\",\"card\",\"check\",\"choose\",\"doors\",\"employ\",\"escort\",\"excuse\",\"favorite\",\"forward\",\"fourth\",\"gonna\",\"hair\",\"happen\",\"heard\",\"hours\",\"management\",\"marshmallows\",\"mind\",\"minute\",\"minutes\",\"ortbo\",\"paintings\",\"petey\",\"quarter\",\"question\",\"read\",\"refinement\",\"sound\",\"tonight\",\"understand\",\"waterfall\",\"wife\",\"woe\",\"wonderful\",\"wondering\"],\"freq\":[32,32,23,21,15,15,12,12,12,11,10,10,9,9,8,8,8,8,8,8,7,7,6,6,5,5,5,5,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3],\"fontFamily\":\"Noto Sans Mono\",\"fontWeight\":\"bold\",\"color\":\"random-dark\",\"minSize\":0,\"weightFactor\":4.5,\"backgroundColor\":\"#030303\",\"gridSize\":0,\"minRotation\":-0.7853981633974483,\"maxRotation\":0.7853981633974483,\"shuffle\":true,\"rotateRatio\":0.4,\"shape\":\"circle\",\"ellipticity\":0.65,\"figBase64\":null,\"hover\":null},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n<center>\n\n::: text\n\nHmm, I'm not seeing that many big words! Maybe we should remove proper names.\n\n:::\n\n</center>\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ntranscripts |> \n  filter(grepl(\"Mil\", speaker)) |>\n  mutate(\n    dialogue = str_replace_all(dialogue, \"’\", \"'\"),\n    dialogue = replace_contraction(dialogue)\n  ) |>\n  unnest_tokens(word, dialogue) |>\n  anti_join(stop_words, by = \"word\") |>\n  mutate(word = gsub(\"'s\", \"\", word)) |>\n    filter(!word %in% c(\"ms\", \"miss\", \"b\", \n                      \"cobel\", \"mark\", \"dylan\", \"helly\", \"irving\",\n                      \"bailiff\", \"casey\", \"dr\", \"eagan\", \"gretchen\",\n                      \"harmony\", \"huang\", \"irv\", \"kier\", \"lawrence\",\n                      \"milchick\", \"petey\", \"rwanda\", \"siena\", \"burt\", \"lumon\", \"scout\", \"mdr\", \"dieter\", \"seth\"),\n         !str_detect(word, \"\\\\d\")) |>\n  count(word) |>\n  filter(n > 1) |>\n  arrange(desc(n)) |>\n  wordcloud2(backgroundColor = \"#030303\",\n             fontFamily = \"Noto Sans Mono\",\n             size = 0.6)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"wordcloud2 html-widget html-fill-item\" id=\"htmlwidget-b57d42ddb42e4e349fdd\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-b57d42ddb42e4e349fdd\">{\"x\":{\"word\":[\"outie\",\"time\",\"innie\",\"office\",\"morning\",\"day\",\"hey\",\"feel\",\"refiners\",\"party\",\"severed\",\"hope\",\"afraid\",\"company\",\"experience\",\"floor\",\"happy\",\"ready\",\"remember\",\"seat\",\"stop\",\"word\",\"ahead\",\"call\",\"called\",\"department\",\"enjoy\",\"evening\",\"eyes\",\"fire\",\"happened\",\"hate\",\"head\",\"hollow\",\"life\",\"love\",\"meantime\",\"night\",\"rest\",\"return\",\"special\",\"start\",\"stay\",\"team\",\"told\",\"balloons\",\"brother\",\"card\",\"check\",\"choose\",\"doors\",\"employ\",\"escort\",\"excuse\",\"favorite\",\"forward\",\"fourth\",\"gonna\",\"hair\",\"happen\",\"heard\",\"hours\",\"management\",\"marshmallows\",\"mind\",\"minute\",\"minutes\",\"ortbo\",\"paintings\",\"quarter\",\"question\",\"read\",\"refinement\",\"sound\",\"tonight\",\"understand\",\"waterfall\",\"wife\",\"woe\",\"wonderful\",\"wondering\",\"agreed\",\"appendix\",\"appreciation\",\"begin\",\"block\",\"board\",\"break\",\"bringing\",\"brought\",\"building\",\"care\",\"chapter\",\"choice\",\"circle\",\"coffee\",\"colleagues\",\"completely\",\"contingency\",\"continue\",\"count\",\"dance\",\"dark\",\"departed\",\"deserve\",\"desk\",\"disclosure\",\"dismissal\",\"door\",\"drink\",\"earth\",\"elevator\",\"employee\",\"excited\",\"eye\",\"fame\",\"family\",\"feelings\",\"feels\",\"file\",\"final\",\"fine\",\"focus\",\"foot\",\"forest\",\"found\",\"founder\",\"funeral\",\"funny\",\"glasgow\",\"goddamn\",\"goodbye\",\"grateful\",\"gratitude\",\"guys\",\"hand\",\"helena\",\"home\",\"honor\",\"hour\",\"ill\",\"imagine\",\"immediately\",\"inform\",\"information\",\"items\",\"knowledge\",\"leader\",\"learned\",\"learning\",\"leave\",\"macrodata\",\"means\",\"meet\",\"melon\",\"milkshake\",\"months\",\"music\",\"natalie\",\"occurred\",\"one\",\"otc\",\"outies\",\"overtime\",\"path\",\"people\",\"period\",\"permanent\",\"personage\",\"personal\",\"pool\",\"pretty\",\"privacy\",\"progress\",\"provide\",\"pull\",\"pus\",\"questions\",\"reached\",\"reaching\",\"refiner\",\"response\",\"retirement\",\"round\",\"rube\",\"safeguard\",\"send\",\"sets\",\"shambolic\",\"shortly\",\"similar\",\"single\",\"sit\",\"smuggle\",\"source\",\"space\",\"spoke\",\"stairwell\",\"stand\",\"statement\",\"step\",\"sudden\",\"table\",\"talk\",\"tallest\",\"tempers\",\"thousand\",\"throw\",\"till\",\"tough\",\"transferred\",\"transition\",\"trust\",\"truth\",\"violated\",\"waffle\",\"waiting\",\"walk\",\"wanna\",\"wellness\",\"wow\",\"wrap\",\"yeah\",\"yesterday\"],\"freq\":[15,15,12,12,10,9,9,8,8,7,7,6,5,5,5,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2],\"fontFamily\":\"Noto Sans Mono\",\"fontWeight\":\"bold\",\"color\":\"random-dark\",\"minSize\":0,\"weightFactor\":7.2,\"backgroundColor\":\"#030303\",\"gridSize\":0,\"minRotation\":-0.7853981633974483,\"maxRotation\":0.7853981633974483,\"shuffle\":true,\"rotateRatio\":0.4,\"shape\":\"circle\",\"ellipticity\":0.65,\"figBase64\":null,\"hover\":null},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n<center>\n::: text\n\nHere's the thing, I don't think there are that many big words! We are of course making some assumptions here (mainly that the words we see in the on screen dialogue are representative of how he speaks off screen), but I think this is reasonable. Ok, maybe the word cloud is not the best way to see this (although we are just doing the same analysis Lumon claims to!), let's instead compare the percentage of multisyllabic words Milchick uses compared to the rest of the characters.\n\n## Syllable count\n\nLet's see if Milchick is really using more syllables than everyone else.\n:::\n\n</center>\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nsyllable_df <- transcripts |>\n  mutate(\n    dialogue = str_replace_all(dialogue, \"’\", \"'\"),\n    dialogue = replace_contraction(dialogue),\n    milchick = grepl(\"Mil\", speaker)\n  ) |>\n  unnest_tokens(word, dialogue) \n\nsafe_syllable_count <- possibly(\n  function(x) qdap::syllable_count(x)$syllables, \n  otherwise = NA_real_\n)\n\nsyllable_df$syllables <- map_dbl(syllable_df$word, safe_syllable_count)\n\nmeans_df <- syllable_df |>\n  filter(!is.na(syllables), syllables != 0) |>\n  group_by(milchick) |>\n  summarise(mean_syllables = mean(syllables),\n            se_syllables = sd(syllables) / sqrt(n()),\n            lcl = mean_syllables - 1.96 * se_syllables,\n            ucl = mean_syllables + 1.96 * se_syllables)\n\np <- syllable_df |>\n  filter(!is.na(syllables), syllables != 0) |>\n  group_by(milchick, syllables) |>\n  summarise(count = n(), .groups = \"drop\") |>\n  group_by(milchick) |>\n  mutate(percent = count/sum(count) * 100) |> \n  ggplot(aes(x = syllables, y = percent, fill = milchick,\n             tooltip = glue::glue(\"{round(percent, 1)}% of the words spoken by {ifelse(milchick, 'Milchick','everyone else')} had {syllables} {ifelse(syllables !=1, 'syllables', 'syllable')}\")))+\n  geom_col_interactive(position = \"dodge\") +\n  scale_fill_manual(values = c(\"TRUE\" = \"#E84646\", \"FALSE\" = \"#3C8DAD\"),\n                    name = \"\",\n                    labels = c(\"Everyone Else\", \"Milchick\")) +\n  scale_color_manual(values = c(\"TRUE\" = \"red\", \"FALSE\" = \"blue\")) +\n  labs(\n    x = \"Syllable Count\",\n    y = \"Percentage of Words\",\n  ) +\n  theme_mdr() +\n  scale_x_continuous(breaks = seq(0, 6, 1),\n                     minor_breaks = seq(0, 6, 0.5)) +\n  theme(\n    legend.position = \"bottom\"\n  )\n#girafe(ggobj = p)\np\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n<center>\n\n::: text\nLooking at the distribution above, it looks like no, in general Milchick is in line with the other speakers. Milchick uses an average of 1.35 (95% CI: 1.33 - 1.37) syllables per word, whereas everyone else is close behind with an average of 1.28 (95% CI: 1.27 - 1.29). While this difference is technically statistically significant, we do not think it is scientifically meaningful.\n:::\n\n::: text\n\n## Common words\n\nOk, maybe by \"big\" Lumon meant not that the words were multisyllabic but rather uncommon. We can use Fry's 1000 word list (Fry (1997)) to help us see if Milchick uses uncommon words more frequently than the other characters. This list claims to contain words that make up 90% of all printed text, let's see if Milchick is using more uncommon words than his counterparts. \n\n:::\n\n</center>\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nwords_df <- transcripts |>\n  mutate(\n    dialogue = str_replace_all(dialogue, \"’\", \"'\"),\n    dialogue = replace_contraction(dialogue),\n    milchick = grepl(\"Mil\", speaker)\n  ) |>\n  unnest_tokens(word, dialogue) \n\nfry_words <- tibble(word = tolower(sw_fry_1000)) |>\n  mutate(is_common = 1) |>\n  distinct()\n\nwords_summary <- words_df |>\n  left_join(fry_words, by = \"word\") |>\n  mutate(is_common = if_else(is.na(is_common), 0, 1)) |>\n  group_by(milchick) |>\n  summarize(\n    total_words = n(),\n    common_words = sum(is_common),\n    p_common = common_words / total_words,\n    se = sqrt(p_common * (1 - p_common) / n()),\n    pct_common = p_common * 100,\n    lcl = (p_common - 1.96 * se) * 100,\n    ucl = (p_common + 1.96 * se) * 100\n  )\n\nggplot(words_summary, \n       aes(x = milchick, y = pct_common, fill = milchick)) +\n  geom_col() +\n  scale_fill_manual(values = c(\"TRUE\" = \"#E84646\", \"FALSE\" = \"#3C8DAD\")) +\n  scale_y_continuous(\"Percentage of Common Words\", limits = c(0, 100)) +\n  scale_x_discrete(\"\", labels = c(\"Everyone else\", \"Milchick\")) +\n  theme_mdr() + \n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n<center>\n\n::: text\n\nWell look at that, Milchick is in line with the rest of the characters! 71.6% of Milchick's words are \"common\" (95% CI: 70.3 - 72.8) compared to 72.8% for everyone else 72.3 - 73.3). Notably, these are both much lower than 90%, as (according to Fry) would be expected in written text, so maybe everyone is using weird vocabulary, but it is not at all unique to Milchick! We will be taking this up with the board.\n\n*This analysis was made possible by the [mdr](https://lucymcgowan.github.io/mdr) R package, which used data originally compiled by [the Severance wiki](https://severance.wiki/). It uses data through season 2 episode 5.*\n:::\n\n::: text\n\n## Addendum\n\nSome folks want to see which words are specific to Milchick -- instead of weighting by frequency like in our top word cloud, we could instead weight by the `tf-idf` (term frequency, inverse document frequency). This basically tells us *which* words are uniquely used by Milchick. I would argue this is *not* what Lumon claimed to do as they were trying to say he was using *too many* big words (which implies frequency), but in any case this is fun!\n\n:::\n\n</center>\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntf_idf <- words_df |>\n  mutate(word = case_when(\n    word == \"innie's\" ~ \"innie\",\n    .default = word\n  )) |>\n  filter(!str_detect(word, \"\\\\d\"), word != \"b's\") |>\n  anti_join(stop_words, by = \"word\") |>\n  count(milchick, word, sort = TRUE) |>\n  bind_tf_idf(word, milchick, n) |>\n  filter(milchick) |>\n  mutate(n = round(tf_idf * 10000, 1)) |>\n  select(word, n) |>\n  arrange(desc(n)) \n\nwordcloud2(tf_idf, \n           backgroundColor = \"#030303\",\n           fontFamily = \"Noto Sans Mono\",\n           size = 0.2)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"wordcloud2 html-widget html-fill-item\" id=\"htmlwidget-fabafaaa4ca04f778403\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-fabafaaa4ca04f778403\">{\"x\":{\"word\":[\"meantime\",\"employ\",\"fourth\",\"marshmallows\",\"agreed\",\"appreciation\",\"block\",\"circle\",\"continue\",\"count\",\"departed\",\"disclosure\",\"dismissal\",\"fame\",\"foot\",\"glasgow\",\"occurred\",\"personage\",\"pull\",\"pus\",\"reached\",\"rube\",\"safeguard\",\"sets\",\"shambolic\",\"shortly\",\"smuggle\",\"statement\",\"sudden\",\"tallest\",\"tough\",\"transferred\",\"transition\",\"violated\",\"waterfall\",\"abdominal\",\"absorb\",\"accessory\",\"accompanied\",\"ached\",\"achieved\",\"action\",\"adjusting\",\"advantage\",\"aggressor\",\"agog\",\"aiding\",\"allowing\",\"almonds\",\"altercation\",\"ama\",\"applause\",\"approach\",\"approve\",\"arrive\",\"assault\",\"assure\",\"attend\",\"authorized\",\"awoke\",\"awoken\",\"bailiff\",\"bathing\",\"bear\",\"beauty\",\"bedevil\",\"bedroll\",\"begged\",\"behave\",\"believed\",\"betterment\",\"bewailing\",\"bistro\",\"biting\",\"bleeding\",\"bloat\",\"brambles\",\"brave\",\"breath\",\"bride\",\"brooks\",\"bud\",\"build\",\"bump\",\"calendar\",\"calls\",\"cameras\",\"canceled\",\"capacity\",\"cart\",\"catered\",\"challenges\",\"chaos's\",\"checks\",\"cheers\",\"chips\",\"choking\",\"cited\",\"claims\",\"cleared\",\"clutter\",\"collegial\",\"comfort\",\"commence\",\"communication\",\"compensation\",\"complicated\",\"compliment\",\"compliments\",\"compunction\",\"concerned\",\"concerns\",\"conditions\",\"confident\",\"consequences\",\"consort\",\"consult\",\"consulted\",\"converse\",\"copious\",\"corrected\",\"country\",\"courtesy\",\"cozies\",\"curtailed\",\"dealing\",\"deaths\",\"deduct\",\"descend\",\"designers\",\"developed\",\"differences\",\"discarded\",\"dissuade\",\"distress\",\"dizzy\",\"dr\",\"driven\",\"drowned\",\"earnest\",\"easily\",\"elonga\",\"emerged\",\"emotionally\",\"enamel\",\"encountered\",\"endearment\",\"enriches\",\"ensure\",\"eternal\",\"eulogy\",\"evoke\",\"experiences\",\"explode\",\"feasible\",\"fellow\",\"fertile\",\"financial\",\"fitting\",\"fixation\",\"floater\",\"forbidden\",\"formal\",\"forthwith\",\"fortunately\",\"fortunes\",\"foyer\",\"fresh\",\"friendships\",\"frigid\",\"gargling\",\"gather\",\"gaunt\",\"genre\",\"glass\",\"grandeur\",\"grief\",\"grieve\",\"grill\",\"grotto\",\"grounds\",\"gullets\",\"handrail\",\"handwriting\",\"hanging\",\"hankering\",\"harder\",\"hare\",\"heal\",\"heat\",\"height\",\"heinous\",\"hills\",\"holiest\",\"hollow's\",\"humbly\",\"hymn\",\"ideographic\",\"incisors\",\"independent\",\"index\",\"inquisitive\",\"insisted\",\"intake\",\"interaction\",\"interactions\",\"international\",\"investigation\",\"jailer\",\"kit\",\"knowing\",\"laid\",\"lawrence\",\"lead\",\"leash\",\"length\",\"lies\",\"listener\",\"luxury\",\"malaysia\",\"management's\",\"manner\",\"maraca\",\"mates\",\"meadows\",\"meaningful\",\"meats\",\"mention\",\"mercy\",\"mill\",\"miracle\",\"missed\",\"moderation\",\"moss\",\"motivator\",\"mournful\",\"mutiny\",\"nanny\",\"national\",\"natural\",\"nature's\",\"nicely\",\"nonexistence\",\"notified\",\"nude\",\"occasionally\",\"official\",\"orgs\",\"orientation's\",\"outhouse\",\"outstanding\",\"overseas\",\"packing\",\"paintball\",\"pair\",\"pal\",\"paperwork\",\"paraphrasing\",\"partake\",\"participation\",\"paycheck\",\"penalty\",\"perchance\",\"performed\",\"persons\",\"phrase\",\"players\",\"ply\",\"policy\",\"pond\",\"popped\",\"potential\",\"preparations\",\"prepped\",\"primary\",\"primed\",\"processed\",\"professional\",\"progeny\",\"proper\",\"protect\",\"protected\",\"punishments\",\"punitive\",\"purged\",\"pursue\",\"puzzling\",\"queries\",\"quietly\",\"raw\",\"reacclimate\",\"reach\",\"reaction\",\"readying\",\"recent\",\"recital\",\"reflected\",\"refreshments\",\"regular\",\"regularly\",\"relations\",\"relegated\",\"remove\",\"rendition\",\"renovation\",\"rescind\",\"resentment\",\"respect\",\"restful\",\"returning\",\"revoke\",\"reward\",\"rhyming\",\"rivaled\",\"roil\",\"rustling\",\"rwanda\",\"sacred\",\"sadist\",\"salt\",\"sanctity\",\"sap\",\"sardines\",\"satiate\",\"scalp\",\"screen\",\"selection\",\"sentient\",\"settle\",\"severely\",\"sharp\",\"shattered\",\"shoulder\",\"signage\",\"silently\",\"site\",\"situated\",\"skull\",\"social\",\"socket\",\"solace\",\"someday\",\"sorts\",\"spaces\",\"spin\",\"stations\",\"stocked\",\"strapping\",\"stray\",\"stressed\",\"stupidity\",\"suffered\",\"sugar\",\"suite\",\"sunrise\",\"supervisory\",\"support\",\"tales\",\"tall\",\"tastier\",\"temper\",\"tents\",\"termed\",\"terminate\",\"terrific\",\"theremin\",\"thickened\",\"thickets\",\"thieving\",\"thoughtfully\",\"throuple\",\"tickling\",\"tightening\",\"timer\",\"tissue\",\"torches\",\"tore\",\"torrent\",\"tri\",\"tucked\",\"tumult\",\"tuned\",\"unauthorized\",\"unsolicited\",\"unwashed\",\"unwell\",\"urge\",\"usual\",\"valediction\",\"vibe\",\"vibration\",\"victim\",\"viscerally\",\"walking\",\"wantonness\",\"washroom\",\"waterfall's\",\"watermelon\",\"weak\",\"weighing\",\"whimper\",\"whore\",\"wife's\",\"wire\",\"woodland\",\"workdays\",\"workspace\",\"wounded\",\"wrath\",\"wrathfully\",\"yearning\",\"dylan\",\"mark\",\"irving\",\"helly\",\"time\",\"outie\",\"innie\",\"ms\",\"office\",\"cobel\",\"morning\",\"day\",\"hey\",\"lumon\",\"feel\",\"huang\",\"kier\",\"miss\",\"refiners\",\"scout\",\"mdr\",\"party\",\"severed\",\"burt\",\"eagan\",\"hope\",\"afraid\",\"company\",\"experience\",\"floor\",\"happy\",\"milchick\",\"ready\",\"remember\",\"seat\",\"stop\",\"word\",\"ahead\",\"call\",\"called\",\"department\",\"dieter\",\"enjoy\",\"evening\",\"eyes\",\"fire\",\"happened\",\"hate\",\"head\",\"life\",\"love\",\"night\",\"rest\",\"return\",\"special\",\"start\",\"stay\",\"team\",\"told\",\"balloons\",\"card\",\"check\",\"choose\",\"doors\",\"escort\",\"excuse\",\"favorite\",\"forward\",\"gonna\",\"hair\",\"happen\",\"heard\",\"helly's\",\"hollow\",\"hours\",\"kier's\",\"mind\",\"minute\",\"minutes\",\"ortbo\",\"paintings\",\"quarter\",\"question\",\"read\",\"refinement\",\"sound\",\"tonight\",\"understand\",\"wonderful\",\"wondering\",\"appendix\",\"begin\",\"board\",\"break\",\"bringing\",\"brother\",\"brought\",\"building\",\"burt's\",\"care\",\"casey\",\"chapter\",\"choice\",\"coffee\",\"colleagues\",\"completely\",\"contingency\",\"dance\",\"dark\",\"deserve\",\"desk\",\"door\",\"drink\",\"earth\",\"elevator\",\"employee\",\"excited\",\"eye\",\"family\",\"feelings\",\"feels\",\"file\",\"final\",\"fine\",\"focus\",\"forest\",\"found\",\"funeral\",\"funny\",\"goddamn\",\"goodbye\",\"grateful\",\"gratitude\",\"guys\",\"hand\",\"harmony\",\"helena\",\"home\",\"honor\",\"hour\",\"ill\",\"imagine\",\"immediately\",\"inform\",\"information\",\"items\",\"knowledge\",\"leader\",\"learned\",\"learning\",\"leave\",\"macrodata\",\"management\",\"means\",\"meet\",\"melon\",\"milkshake\",\"months\",\"music\",\"natalie\",\"one's\",\"outie's\",\"outies\",\"overtime\",\"path\",\"people\",\"period\",\"permanent\",\"personal\",\"petey\",\"pool\",\"pretty\",\"privacy\",\"progress\",\"provide\",\"questions\",\"reaching\",\"refiner\",\"response\",\"retirement\",\"round\",\"send\",\"seth\",\"similar\",\"single\",\"sit\",\"source\",\"space\",\"spoke\",\"stairwell\",\"stand\",\"step\",\"table\",\"talk\",\"tempers\",\"thousand\",\"throw\",\"till\",\"trust\",\"truth\",\"waffle\",\"waiting\",\"walk\",\"wanna\",\"wellness\",\"wife\",\"woe's\",\"wow\",\"wrap\",\"yeah\",\"yesterday\",\"accept\",\"access\",\"actions\",\"affections\",\"ago\",\"alert\",\"allergic\",\"amazing\",\"animal\",\"announcements\",\"answers\",\"apologies\",\"apologize\",\"assume\",\"ate\",\"attendance\",\"avoid\",\"awaken\",\"awesome\",\"bar\",\"based\",\"behavior\",\"bereavement\",\"bet\",\"black\",\"blessings\",\"blue\",\"blueprints\",\"bomb\",\"branch\",\"breakfast\",\"briefly\",\"brings\",\"broke\",\"brother's\",\"buy\",\"careful\",\"cares\",\"carol\",\"carry\",\"catch\",\"caught\",\"cave\",\"challenge\",\"chance\",\"chat\",\"cheer\",\"chemistry\",\"chief\",\"chose\",\"close\",\"closet\",\"cobel's\",\"code\",\"colloquially\",\"coming\",\"commandeered\",\"conducting\",\"conscious\",\"contact\",\"core\",\"courage\",\"cozy\",\"cries\",\"cruise\",\"current\",\"cut\",\"days\",\"deal\",\"dear\",\"death\",\"decision\",\"deserves\",\"desire\",\"destroyed\",\"detectors\",\"devon\",\"dictated\",\"died\",\"difficult\",\"directly\",\"disappointed\",\"discuss\",\"disguise\",\"distracting\",\"doctor\",\"double\",\"dozing\",\"drew\",\"drown\",\"drummond\",\"duty\",\"earned\",\"effective\",\"egg\",\"eggs\",\"elevators\",\"elongated\",\"em\",\"emergency\",\"employment\",\"environment\",\"equipped\",\"erotic\",\"ether\",\"events\",\"everything's\",\"excellent\",\"executive\",\"existed\",\"expected\",\"failed\",\"fair\",\"fall\",\"father\",\"feeling\",\"files\",\"fill\",\"fix\",\"follow\",\"food\",\"footage\",\"forbids\",\"forever\",\"form\",\"founder\",\"founder's\",\"friend\",\"friends\",\"front\",\"fruit\",\"fucked\",\"fun\",\"gala\",\"game\",\"gemma\",\"gentlemen\",\"george\",\"ghost\",\"gift\",\"graner\",\"grasp\",\"gretchen\",\"gråkappan\",\"guess\",\"hale\",\"half\",\"hall\",\"handbook\",\"hands\",\"hard\",\"heads\",\"hearing\",\"helped\",\"hip\",\"hire\",\"history\",\"hold\",\"hoped\",\"house\",\"idea\",\"including\",\"industries\",\"innies\",\"installed\",\"intended\",\"intention\",\"interview\",\"involved\",\"irv\",\"irving's\",\"issue\",\"jesus\",\"job\",\"joke\",\"jokes\",\"key\",\"ladies\",\"late\",\"laugh\",\"lay\",\"learn\",\"left\",\"level\",\"lift\",\"light\",\"line\",\"listen\",\"literally\",\"locked\",\"looked\",\"lumon's\",\"macrodats\",\"makes\",\"manage\",\"mark's\",\"mde\",\"mdr's\",\"measure\",\"messages\",\"microphones\",\"milk\",\"mine\",\"mistake\",\"moments\",\"monday\",\"mouth\",\"moved\",\"murder\",\"names\",\"nice\",\"note\",\"occurrence\",\"officially\",\"opinion\",\"opportunity\",\"option\",\"otc\",\"otc's\",\"outburst\",\"outdoor\",\"paid\",\"pain\",\"painful\",\"passed\",\"passes\",\"past\",\"paupers\",\"perk\",\"perks\",\"perpetuity\",\"person\",\"petey's\",\"photo\",\"physical\",\"piece\",\"planet\",\"plans\",\"play\",\"pleasure\",\"position\",\"pre\",\"prefer\",\"principle\",\"principles\",\"print\",\"privileges\",\"process\",\"productive\",\"promise\",\"protocol\",\"provided\",\"quota\",\"rare\",\"recall\",\"received\",\"refining\",\"reform\",\"reforms\",\"refrain\",\"regret\",\"relax\",\"remain\",\"remind\",\"remotely\",\"reporting\",\"request\",\"requested\",\"research\",\"responsibility\",\"retiring\",\"retreat\",\"root\",\"run\",\"sad\",\"sadly\",\"safely\",\"safety\",\"save\",\"scissor\",\"security\",\"seek\",\"sense\",\"sensitive\",\"set\",\"severance\",\"severing\",\"shame\",\"share\",\"shit\",\"shown\",\"shut\",\"siena\",\"sister's\",\"skin\",\"smiles\",\"soil\",\"song\",\"sounded\",\"speech\",\"spend\",\"spending\",\"spent\",\"spirit\",\"standard\",\"started\",\"status\",\"story\",\"straight\",\"stuff\",\"successfully\",\"suddenly\",\"supply\",\"suppose\",\"supposed\",\"surface\",\"sweet\",\"switch\",\"sympathize\",\"takes\",\"taking\",\"talking\",\"tamed\",\"teasing\",\"tech\",\"telling\",\"text\",\"thankfully\",\"thinking\",\"thirty\",\"threatened\",\"thrilled\",\"tomorrow\",\"twin\",\"unsevered\",\"upstairs\",\"valuable\",\"video\",\"violent\",\"visitation\",\"voyage\",\"wait\",\"wake\",\"waking\",\"walked\",\"watch\",\"water\",\"weeks\",\"win\",\"woe\",\"woke\",\"woman\",\"words\",\"workers\",\"world\",\"worry\",\"writing\",\"wrong\"],\"freq\":[17.4,13.1,13.1,13.1,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,8.699999999999999,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,4.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"fontFamily\":\"Noto Sans Mono\",\"fontWeight\":\"bold\",\"color\":\"random-dark\",\"minSize\":0,\"weightFactor\":2.068965517241379,\"backgroundColor\":\"#030303\",\"gridSize\":0,\"minRotation\":-0.7853981633974483,\"maxRotation\":0.7853981633974483,\"shuffle\":true,\"rotateRatio\":0.4,\"shape\":\"circle\",\"ellipticity\":0.65,\"figBase64\":null,\"hover\":null},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n<center>\n\n::: text\n\n## Zipf Frequency\n\nOur refiner [Leopold](https://github.com/LeopoldTal) pointed out that we could use the `Zipf frequency` of the words to get a more granular look at whether Milchick is using common language (compared to our Fry approach which just dichotomized as common/not common). As the title of my main blog, [livefreeordichotomize](https://livefreeordichotomize.com), would suggest, I am ALWAYS here to avoid dichotomizing. The `Zipf frequency` is the log (base 10) of the number of times a word appears per billion words (i.e., a word with `Zipf frequency` of 3 appears once per million words). Ok, let's try that! We've calculated this for our main guy, Milchick, along with some other characters to compare him to and plotted the density. The dashed lines represent the medians.\n\n:::\n\n</center>\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(reticulate)\nwords_df <- transcripts |> \n  mutate(\n    dialogue = str_replace_all(dialogue, \"’\", \"'\"),\n    dialogue = replace_contraction(dialogue),\n    character = case_when(\n      grepl(\"Mil\", speaker) ~ \"Milchick\",\n      grepl(\"Cob\", speaker) ~ \"Cobel\",\n      grepl(\"Mark\", speaker) ~ \"Mark\",\n      grepl(\"Hel\", speaker) ~ \"Helly/Helena\",\n      grepl(\"Irv\", speaker) ~ \"Irving\",\n      grepl(\"Huang\", speaker) ~ \"Ms. Huang\",\n      grepl(\"Dylan\", speaker) ~ \"Dylan\",\n      .default = \"Everyone else\"\n    )\n  ) |>\n  unnest_tokens(word, dialogue) |>\n  anti_join(stop_words, by = \"word\") |>\n  mutate(word = gsub(\"'s\", \"\", word))\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code  code-fold=\"true\"}\nfrom wordfreq import zipf_frequency\n\ndf = r.words_df\nzipf = df['word'].apply(lambda word: zipf_frequency(word, 'en'))\nr.zipf = zipf.tolist()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nwords_df$zipf <- as.numeric(zipf)\n\nwords_df <- words_df |>\n  filter(zipf > 0)\n\nzipf_medians <- words_df |>\n  group_by(character) |>\n  summarize(median_zipf = median(zipf))\n\nggplot(words_df, aes(x = zipf, fill = character)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(data = zipf_medians, \n             aes(xintercept = median_zipf,\n                 color = character), \n             linetype = \"dashed\") +\n  geom_label(data = zipf_medians, aes(label = glue::glue(\"Median: {round(median_zipf,1)}\"),\n                                      x = 2, y = 0.5),\n             inherit.aes = FALSE) +\n  facet_wrap(~character) +\n  labs(\n    x = \"Zipf frequency (log10 occurances per a billion words)\",\n    y = \"Density\"\n  ) +\n  theme_mdr() + \n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n<center>\n\n::: text\nFascinating, this is a great view of the language! Of the ones we examined, most of our main characters have a median Zipf frequency between 4.7 (Cobel) and 5 (Ms. Huang), with the exception of Milchick (4.6) and Irving (4.6). Now, one angle is that Milchick is using too big of words, but another is that Ms. Huang, his likely accuser, is just using too basic of words compared to the others. Or maybe she is onto something, his Zipf frequency distribution is (statistically) significantly different from everyone else (p = <0.001).\n\n:::\n\n</center>\n\n\n\n::: {.cell}\n\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../site_libs/wordcloud2-0.0.1/wordcloud.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/wordcloud2-0.0.1/wordcloud2-all.js\"></script>\n<script src=\"../site_libs/wordcloud2-0.0.1/hover.js\"></script>\n<script src=\"../site_libs/wordcloud2-binding-0.2.2/wordcloud2.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}